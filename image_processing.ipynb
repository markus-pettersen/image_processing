{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "410aff76",
   "metadata": {},
   "source": [
    "# Task 46: Capstone Project VI\n",
    "Using the data provided in the MNIST database, train a random forest model that can correctly classify the hand written numbers (displayed in a 28 by 28 pixel image).\n",
    "## Initial set-up\n",
    "Before the model can be instantiated, the correct modules need to be imported and the dataset loaded.\n",
    "### Importing the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f420e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9923be39",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "Import the MNIST dataset as a pandas dataframe and assign to the variable <code>train_data</code>. The training data contains 60000 hand written numerals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57195da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('mnist_train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f7c5fc",
   "metadata": {},
   "source": [
    "The dataset is divided into labels (denoting the number) and values for the amount of grey in each pixel in a 28 by 28 grid. The labels will be assigned to a variable y (the dependent variable) and the vectorised image as X (the independent variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d6bc071",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('label', axis=1).values\n",
    "y = train_data[['label']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0fbd6c",
   "metadata": {},
   "source": [
    "### Examine the dataset\n",
    "To get a better idea of the data in question, I arbitrarily selected a few records from the dataset, first reshape the X data into the original 60000 by 28 by 28:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d36d6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6afa786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(60000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb03785b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selection_list = [2010, 43, 3001]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for count, value in enumerate(selection_list):\n",
    "    plt.subplot(1, 3, count + 1)\n",
    "    plt.imshow(X[value, :,:], cmap='gray_r')\n",
    "    plt.title(f'Entry {value}')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdba2f9",
   "metadata": {},
   "source": [
    "From above, the numbers in the dataset are grey-scale images of numbers displayed in a 28 by 28 pixel image. Next, look at the labels for each of the entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5346e275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry 2010: [2]\n",
      "Entry 43: [9]\n",
      "Entry 3001: [0]\n"
     ]
    }
   ],
   "source": [
    "for value in selection_list:\n",
    "    print(f'Entry {value}: {y[value]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bed07a",
   "metadata": {},
   "source": [
    "From above, the labels are correct for each entry. For the random forest algorithm, the data must be 1 dimension so the independent variables need to be revectorised (or in this case, taken from the original DF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d20677",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('label', axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff8ed7d",
   "metadata": {},
   "source": [
    "Convert y from a column vector to a 1D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf3ea425",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0727551b",
   "metadata": {},
   "source": [
    "## Model Set-up\n",
    "### Motivation for training, development and test sets\n",
    "The data is first divided into a training set and a test set. The training set can be further divided into a training set and a development set (also known as a validation set). \n",
    "#### Training\n",
    "The model is initially trained using the training set. This is the process where the model has access to the labels and images, and attempts to establish connections between the values of the independent varaibles and the label. A successful model should be able to generalise the patterns learnt in this stage to previously unseen data. \n",
    "#### Development\n",
    "After an initial model has been trained, the development set is used to measure how well it performs. Here, the model sees the images, but not the labels and must use it's training to classify each number. At this point, the model's hyperparameters can be tweaked to get better performance. \n",
    "#### Test\n",
    "Finally, once the model is finished, the unseen test data is used in the same way as the development set to measure the model's overall accuracy. However, during this stage, the model can no longer be altered. The test set is used to determine the model's ultimate accuracy.\n",
    "\n",
    "### Train-(development)-test split\n",
    "Divide the data into training data and test data (here <i>test</i> data refers to the development set. A separate file containing the test data will be used as the test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe6669c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ccd76",
   "metadata": {},
   "source": [
    "Check that the distribution of labels is equal between the train set and the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79e6e6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.112375\n",
       "7    0.104417\n",
       "3    0.102188\n",
       "2    0.099292\n",
       "9    0.099146\n",
       "0    0.098708\n",
       "6    0.098625\n",
       "8    0.097521\n",
       "4    0.097375\n",
       "5    0.090354\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3752e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.112333\n",
       "7    0.104417\n",
       "3    0.102167\n",
       "2    0.099333\n",
       "9    0.099167\n",
       "0    0.098750\n",
       "6    0.098667\n",
       "8    0.097500\n",
       "4    0.097333\n",
       "5    0.090333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "09b212a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841fc90d",
   "metadata": {},
   "source": [
    "Both sets have a relatively equal distribution. As a whole, the dataset appears to contain more 1 and 7s and few 5s. This is probably intentional from the authors because 1 and 7 can often be confused (would required more data to make a clear distinction) while 5 is usually easily identified.\n",
    "### Random Forest model\n",
    "Now the data is divided, the Random Forest model can be instantiated. Intially set the number of trees in the forest to ten. This allows us to see a rough estimate of the model's accuracy quickly without using too much processing power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "421d7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_basic = RandomForestClassifier(n_estimators=10, random_state=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9aafb",
   "metadata": {},
   "source": [
    "Fit the model to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c16b73a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=10, n_jobs=-1, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=10, n_jobs=-1, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_basic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12426a9b",
   "metadata": {},
   "source": [
    "Use the model to predict labels for the test set (development set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0c9ec5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_basic = rf_basic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1b36a3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459166666666666"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffbd7da",
   "metadata": {},
   "source": [
    "An inital accuracy of 94.6% shows that the model is suitable and fits the data well. However the accuracy can be improved by tuning the hyperparameters.\n",
    "#### Hyperparameters\n",
    "Retrieve the parameters from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3e10d92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 70,\n",
       " 'n_jobs': -1,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f336289d",
   "metadata": {},
   "source": [
    "The maximum number of features (independent variables) for each tree is the square root of the total number of features. In this case, there are 784 features, so each tree has a maximum of 28 features. The minimum number of trees necessary to use all the features would be 28 (higher than 10). In theory, there should be no penalty to using more trees (other than processing time). Try n_estimator = 140 (28 times 5; ensures all features have a good chance of being selected). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9bfbbb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=140, n_jobs=-1, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=140, n_jobs=-1, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=140, n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=140, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f94a3814",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "431a0a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689166666666666"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355506d6",
   "metadata": {},
   "source": [
    "With 140 trees, the new accuracy is 96.9% (2.3% improvement). With 12000 labels in the test set, this corresponds to correctly predicting 276 more samples. Can the accuracy be further improved with 280 trees (10 multiplied by 28):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e3719ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=280, n_jobs=-1, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=280, n_jobs=-1, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=280, n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_max = RandomForestClassifier(n_estimators=280, random_state=1, n_jobs=-1)\n",
    "rf_max.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a94a950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_max = rf_max.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2e866e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9691666666666666"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369bdd32",
   "metadata": {},
   "source": [
    "With 280 trees, the new accuracy is 96.9%. This roughly the same as with 140 (less than 0.1% better). Therefore, I don't think the increase in accuracy is worth the processing time. The number of estimators in the final model will be set to 140.\n",
    "### Final predictions\n",
    "Next, import the test data and measure the final accuracy of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e03b033d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      7    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data = pd.read_csv('mnist_test.csv')\n",
    "final_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef2bbc6",
   "metadata": {},
   "source": [
    "Separate into labels and features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "65d30bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = final_test_data.drop('label', axis=1).values\n",
    "y_final = final_test_data[['label']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6080c",
   "metadata": {},
   "source": [
    "Convert y from a column vector to a 1D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7cbed02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = y_final.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deaa98e",
   "metadata": {},
   "source": [
    "Use the model <code>rf</code> to predict the values of <code>y_final</code> from <code>X_final</code> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "42482bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = rf.predict(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9e91e9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9693"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_final, y_pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583d818c",
   "metadata": {},
   "source": [
    "The final accuracy on the test set is similar to that for the development set (96.9%)\n",
    "### Final model summary\n",
    "The model performed well on the test set. Examine the confusion matrix to see which classes were easy and which classes were less successful. Columns show the predicts, rows are the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2e205498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1123</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>968</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>954</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>860</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>936</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>986</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>932</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3    4    5    6    7    8    9\n",
       "0  970     1     0    0    0    2    3    1    2    1\n",
       "1    0  1123     2    3    0    1    3    0    2    1\n",
       "2    6     0  1000    3    3    0    4    8    8    0\n",
       "3    0     0    13  968    0   10    0    9    8    2\n",
       "4    1     0     2    0  954    0    4    0    3   18\n",
       "5    2     1     1    9    4  860    6    1    5    3\n",
       "6    6     3     2    0    3    3  936    0    5    0\n",
       "7    1     4    22    1    1    0    0  986    1   12\n",
       "8    3     0     4    8    6    5    4    4  932    8\n",
       "9    4     4     2   10   10    4    1    4    6  964"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_final, y_pred_final)\n",
    "c_columns = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "pd.DataFrame(c_matrix, columns=c_columns, index=c_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f422b6",
   "metadata": {},
   "source": [
    "The number of images for each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "01abb7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1135\n",
       "2    1032\n",
       "7    1028\n",
       "3    1010\n",
       "9    1009\n",
       "4     982\n",
       "0     980\n",
       "8     974\n",
       "6     958\n",
       "5     892\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_final).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b286e4",
   "metadata": {},
   "source": [
    "Based on the above information, the model is very successful at predicting 0, 1 and 6. Very few of those images were incorrectly classifed. The model incorrectly predicted a 7 as a 2 on 22 occasions, and a 4 as a 9 on 18 occassions. However, these incorrect predictions are vastly outnumbered by correct predictions.\n",
    "\n",
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "37b79722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.95      0.97      0.96      1032\n",
      "           3       0.97      0.96      0.96      1010\n",
      "           4       0.97      0.97      0.97       982\n",
      "           5       0.97      0.96      0.97       892\n",
      "           6       0.97      0.98      0.98       958\n",
      "           7       0.97      0.96      0.97      1028\n",
      "           8       0.96      0.96      0.96       974\n",
      "           9       0.96      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_final, y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46132ac5",
   "metadata": {},
   "source": [
    "The classification report supports the confusion matrix. 0, 1 and 6 have a high f1-score and the lowest f1-scores are for 3, 8 and 9.\n",
    "#### Improved efficiency\n",
    "It may be possible to improve the model more. In the dataframe there are a lot of columns that contain all 0. This implies that all images contain white space in that particular pixel. By dropping these columns, we can reduce the number of features, and require fewer trees to reach the same accuracy. This may also increase the accuracy of the predictions. We are  interested in what features distinguish numbers, so features common to all the numbers in the dataset are unnecessary and may reduce accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d872d88",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
